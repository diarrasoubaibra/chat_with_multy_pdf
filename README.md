# üìö Chat avec plusieurs PDFs (RAG + Streamlit)

Ce projet est une application Streamlit qui vous permet de **poser des questions en langage naturel** sur plusieurs fichiers PDF, gr√¢ce √† une approche **RAG (Retrieval-Augmented Generation)**.

L'application extrait le texte de vos PDF, le segmente, le vectorise avec des embeddings de Hugging Face, et vous permet d'interagir avec vos documents via un mod√®le LLM h√©berg√© (LLaMA-2 via HuggingFace Hub ou OpenRouter).

---

## ‚ú® Fonctionnalit√©s

- üì• Chargement de plusieurs fichiers PDF
- üìÑ Extraction et d√©coupage intelligent du texte
- üîé Recherche vectorielle avec FAISS
- ü§ñ Chat contextuel avec m√©moire de conversation
- üß† Mod√®les LLM gratuits via HuggingFace Hub ou OpenRouter
- üåê Interface simple et interactive via Streamlit

---

## üß∞ Technologies utilis√©es

| Composant                    | Description                                           |
|-----------------------------|-------------------------------------------------------|
| `Streamlit`                 | Interface web interactive                            |
| `LangChain`                 | Orchestration RAG et cha√Æne conversationnelle        |
| `HuggingFaceEmbeddings`     | Encodage des textes pour la recherche s√©mantique     |
| `FAISS`                     | Base vectorielle pour la similarit√© de texte         |
| `LLaMA 2` ou `Mistral`      | Mod√®les LLM (gratuits via HuggingFace Hub ou OpenRouter) |
| `PyPDF2`                    | Extraction de texte depuis des fichiers PDF          |
| `.env`                      | Gestion s√©curis√©e des cl√©s API                       |

---

## üöÄ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/votre-utilisateur/multi-pdf-chat-rag.git
cd multi-pdf-chat-rag
```
### 2. Cr√©er et activer un environnement virtuel
```
python -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
```
### 3. Installer les d√©pendances
```
pip install -r requirements.txt
```
### 4. Cr√©er un fichier .env
```
HUGGINGFACEHUB_API_KEY=your_huggingface_token
# ou si vous utilisez OpenRouter √† la place :
OPENROUTER_API_KEY=your_openrouter_key
```
### Ex√©cution de l'application
```
streamlit run app.py
```
Puis ouvrez l‚Äôapplication dans votre navigateur √† l‚Äôadresse [http://localhost:8501]

## Personnalisation
### Changer de mod√®le LLM
**Dans get_conversation_chain() :**

**- Pour Hugging Face :**
```
from langchain_community.llms import huggingface_hub
llm = huggingface_hub(
    repo_id="meta-llama/Llama-2-7b-chat-hf",
    token=os.getenv("HUGGINGFACEHUB_API_KEY"),
    model_kwargs={"temperature": 0.1, "max_new_tokens": 512}
)
```
**- Pour OpenRouter :**
```
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
    model="mistralai/mistral-7b-instruct",
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=os.getenv("OPENROUTER_API_KEY")
)
```

